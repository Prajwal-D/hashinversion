{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ba999b-7481-4217-9c08-342ff12753d1",
   "metadata": {},
   "source": [
    "Notes to self:\n",
    "\n",
    "Need to fix the global variables to never mutate, probably replace them, confusing as hell\n",
    "\n",
    "DO NOT CHANGE NUM_BYTES from 4 or there will be dragons!!! I really don't know why it is working as it is, especially since it should be 2!!!\n",
    "\n",
    "amount of hashes hardcoded = 2\n",
    "\n",
    "dpt significance = ends with 8 zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a946f5bc-352c-40f7-81bd-8371571e3d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:jupyter_black:config: {'line_length': 79, 'target_versions': {<TargetVersion.PY310: 10>}}\n"
     ]
    }
   ],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(\n",
    "    line_length=79,\n",
    "    verbosity=\"DEBUG\",\n",
    "    target_version=black.TargetVersion.PY310,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a12e25d7-f5ad-47a5-918d-7c5778baf510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import hashlib as h\n",
    "import time\n",
    "import numpy as np\n",
    "import definitions as defs\n",
    "\n",
    "from multiprocessing import shared_memory, cpu_count, Value\n",
    "import concurrent.futures\n",
    "\n",
    "NUM_HASHES = 10\n",
    "\n",
    "hash_data_type = np.dtype(\"S4\")\n",
    "num_bytes = 4\n",
    "zeros = 0\n",
    "list_of_password_extractions = []\n",
    "list_of_colliding_hashes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46cb240-8254-441b-bab2-78af9b612652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Helper function to visualise passwords as hex strings\"\"\"\n",
    "\n",
    "\n",
    "def bytes_to_string(bytes_data):\n",
    "    intRepresentation = int.from_bytes(bytes_data, \"big\")\n",
    "    return \"0x{0:x}\".format(intRepresentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4dfe77d-6288-41b0-a875-814424342c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Write the generated results to a .txt file\"\"\"\n",
    "\n",
    "\n",
    "def writeResults(p):\n",
    "    f = open(\"SDPTemp.txt\", \"a\")\n",
    "    for i in range(0, 13):\n",
    "        f.write(str(p[i]) + \"--\")\n",
    "    f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73825302-b87b-47f2-95e2-e61a2748a15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00\\x01'\n",
      "b'\\x01\\x00'\n"
     ]
    }
   ],
   "source": [
    "table_id = 1\n",
    "table_id_bytes = table_id.to_bytes(2, \"big\")\n",
    "print(table_id_bytes)\n",
    "print(table_id_bytes[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30da5436-2872-4e06-b8e2-48155442780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate random password of a given size, hashed NUM_HASHES times\"\"\"\n",
    "\n",
    "\n",
    "def get_random_password(size):\n",
    "    global NUM_HASHES\n",
    "\n",
    "    password_gen_incomplete = True\n",
    "    while password_gen_incomplete:\n",
    "        new = random.getrandbits(size)\n",
    "        password = new.to_bytes(num_bytes, \"big\")\n",
    "\n",
    "        hashed_value = password\n",
    "        for i in range(NUM_HASHES):\n",
    "            if defs.is_dp(password, size):\n",
    "                print(\"bad pass!\")\n",
    "                # break     # we're gonna allow generating bad passwords\n",
    "            hashed_value = defs.apply_hash(hashed_value, size)\n",
    "            if i == NUM_HASHES - 1:\n",
    "                password_gen_incomplete = False\n",
    "        ## if a hashed_value in this loop ends with eight 0s, this password can't be reversed!\n",
    "\n",
    "    return (password, hashed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7d09bb-99b8-4d9e-9c62-8f4e15f78a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate a list of random hashes to attempt to invert\"\"\"\n",
    "\n",
    "\n",
    "def generate_passwords(num, num_bits):\n",
    "    my_passwords = list()\n",
    "    for i in range(num):\n",
    "        my_passwords.append(get_random_password(num_bits))\n",
    "    return my_passwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d6775e-3230-42aa-9316-f478b2b0ac71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x99\\x00'\n",
      "b'\\x00\\x00'\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "current = b\"\\x99\\x00\"\n",
    "last_8_bits_mask = bytes(x & y for x, y in zip(b\"\\x00\\xff\", current))[\n",
    "    :num_bytes\n",
    "]\n",
    "\n",
    "print(current)\n",
    "print(last_8_bits_mask)\n",
    "print(int.from_bytes(last_8_bits_mask, \"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3306aaf-bf2e-4e92-9cb1-b50c1d681466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00\\x00\\xff'\n"
     ]
    }
   ],
   "source": [
    "test_bytes = b\"\\xff\"\n",
    "test_bytes = b\"\\x00\" + test_bytes\n",
    "test_bytes = b\"\\x00\" + test_bytes\n",
    "\n",
    "print(test_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc5db5f-c378-41ee-b0bb-2b29d928c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Method to search through the chains of the dpt tables, returns true or false and\n",
    "the number of collisions / false alarms that occurred\"\"\"\n",
    "\n",
    "\n",
    "def search_tables(\n",
    "    tp,\n",
    "    y,\n",
    "    start_points,\n",
    "    end_points,\n",
    "    no_tables,\n",
    "    no_chains,\n",
    "    chain_length,\n",
    "    input_size,\n",
    "):\n",
    "    global list_of_password_extractions\n",
    "    global list_of_colliding_hashes\n",
    "\n",
    "    global NUM_HASHES\n",
    "\n",
    "    true_password = tp\n",
    "    total_false_alarms = 0\n",
    "    total_gen_hashes = 0\n",
    "    total_false_alarm_hashes = 0\n",
    "    total_success_hashes = 0\n",
    "\n",
    "    success = Value(\"i\", 0)\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(\n",
    "        max_workers=cpu_count() - 4, # leave 4 logical processors open for OS\n",
    "        initializer=defs.init_shared_bool,\n",
    "        initargs=(success)\n",
    "    ) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                defs.search_chains,\n",
    "                tp,\n",
    "                y,\n",
    "                start_points,\n",
    "                end_points,\n",
    "                t,\n",
    "                no_chains,\n",
    "                chain_length,\n",
    "                input_size,\n",
    "                NUM_HASHES,\n",
    "            )\n",
    "            for t in range(no_tables)\n",
    "        ]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result[0]:\n",
    "                if tp == result[5]:\n",
    "                    list_of_password_extractions.append(\n",
    "                        [\n",
    "                            bytes_to_string(tp),\n",
    "                            bytes_to_string(y),\n",
    "                            bytes_to_string(result[5]),\n",
    "                        ]\n",
    "                    )\n",
    "                else:\n",
    "                    list_of_colliding_hashes.append(\n",
    "                        [\n",
    "                            bytes_to_string(tp),\n",
    "                            bytes_to_string(y),\n",
    "                            bytes_to_string(result[5]),\n",
    "                        ]\n",
    "                    )\n",
    "            total_false_alarms += result[1]\n",
    "            total_gen_hashes += result[2]\n",
    "            total_false_alarm_hashes += result[3]\n",
    "            total_success_hashes += result[4]\n",
    "\n",
    "    # for t in range(no_tables):\n",
    "    #     result = defs.search_chains(\n",
    "    #         tp,\n",
    "    #         y,\n",
    "    #         start_points,\n",
    "    #         end_points,\n",
    "    #         t,\n",
    "    #         no_chains,\n",
    "    #         chain_length,\n",
    "    #         input_size,\n",
    "    #         NUM_HASHES,\n",
    "    #     )\n",
    "    #     if result[0]:\n",
    "    #         if tp == result[5]:\n",
    "    #             list_of_password_extractions.append(\n",
    "    #                 [\n",
    "    #                     bytes_to_string(tp),\n",
    "    #                     bytes_to_string(y),\n",
    "    #                     bytes_to_string(result[5]),\n",
    "    #                 ]\n",
    "    #             )\n",
    "    #         else:\n",
    "    #             list_of_colliding_hashes.append(\n",
    "    #                 [\n",
    "    #                     bytes_to_string(tp),\n",
    "    #                     bytes_to_string(y),\n",
    "    #                     bytes_to_string(result[5]),\n",
    "    #                 ]\n",
    "    #             )\n",
    "    #         return (\n",
    "    #             True,\n",
    "    #             total_false_alarms + result[1],\n",
    "    #             total_gen_hashes + result[2],\n",
    "    #             total_false_alarm_hashes + result[3],\n",
    "    #             total_success_hashes + result[4],\n",
    "    #         )\n",
    "    #     total_false_alarms += result[1]\n",
    "    #     total_gen_hashes += result[2]\n",
    "    #     total_false_alarm_hashes += result[3]\n",
    "    #     total_success_hashes += result[4]\n",
    "\n",
    "    succeeded = (True if success.value > 0 else False,)\n",
    "    return (\n",
    "        succeeded,\n",
    "        total_false_alarms,\n",
    "        total_gen_hashes,\n",
    "        total_false_alarm_hashes,\n",
    "        total_success_hashes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b75707ea-3016-4627-b02e-ae8fb135e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shared_sdp_table_block(no_tables, no_chains):\n",
    "    global hash_data_type\n",
    "\n",
    "    tmp_zero_arr = np.zeros(shape=(no_tables, no_chains), dtype=hash_data_type)\n",
    "\n",
    "    shm_start_points = shared_memory.SharedMemory(\n",
    "        create=True, size=tmp_zero_arr.nbytes, track=False\n",
    "    )\n",
    "    start_points = np.ndarray(\n",
    "        tmp_zero_arr.shape, dtype=hash_data_type, buffer=shm_start_points.buf\n",
    "    )\n",
    "    start_points[:] = tmp_zero_arr[:]\n",
    "\n",
    "    shm_end_points = shared_memory.SharedMemory(\n",
    "        create=True, size=tmp_zero_arr.nbytes, track=False\n",
    "    )\n",
    "    end_points = np.ndarray(\n",
    "        tmp_zero_arr.shape, dtype=hash_data_type, buffer=shm_end_points.buf\n",
    "    )\n",
    "    end_points[:] = tmp_zero_arr[:]\n",
    "\n",
    "    return start_points, shm_start_points, end_points, shm_end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9afccdee-ebb6-4d77-a6b3-9db605ee2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reduction on Distinguished point with fixed length chains method\"\"\"\n",
    "\n",
    "\n",
    "def fixed_len_dpt(no_tables, no_chains, chain_len, no_iterations, hash_size):\n",
    "\n",
    "    false_alarms = 0\n",
    "    inverse_success = 0\n",
    "    gen_hashes = 0\n",
    "    false_alarm_hashes = 0\n",
    "    success_hashes = 0\n",
    "    global zeros\n",
    "    global num_bytes\n",
    "    global hash_data_type\n",
    "\n",
    "    num_bytes = hash_size // 8\n",
    "    zeros = 0\n",
    "    zeros = zeros.to_bytes(num_bytes, \"big\")\n",
    "    data_type_string = \"S\" + str(num_bytes)\n",
    "    hash_data_type = np.dtype(data_type_string)\n",
    "\n",
    "    # time sdpt table creation\n",
    "    start = time.time()\n",
    "\n",
    "    start_points, shm_start_points, end_points, shm_end_points = (\n",
    "        create_shared_sdp_table_block(no_tables, no_chains)\n",
    "    )\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(\n",
    "        max_workers=cpu_count() - 4  # leave 4 logical processors open for OS\n",
    "    ) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                defs.gen_table,\n",
    "                hash_data_type,\n",
    "                no_chains,\n",
    "                hash_size,\n",
    "                chain_len,\n",
    "                table_id,\n",
    "            )\n",
    "            for table_id in range(no_tables)\n",
    "        ]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            start_points[future.result()[2]] = future.result()[0]\n",
    "            end_points[future.result()[2]] = future.result()[1]\n",
    "\n",
    "    end = time.time()\n",
    "    tables_time = end - start\n",
    "\n",
    "    my_passwords = generate_passwords(no_iterations, hash_size)\n",
    "\n",
    "    # time search algorithm\n",
    "    start = time.time()\n",
    "    for i in range(no_iterations):\n",
    "        x = search_tables(\n",
    "            my_passwords[i][0],\n",
    "            my_passwords[i][1],\n",
    "            start_points,\n",
    "            end_points,\n",
    "            no_tables,\n",
    "            no_chains,\n",
    "            chain_len,\n",
    "            hash_size,\n",
    "        )\n",
    "        false_alarms += x[1]\n",
    "        if x[0]:\n",
    "            inverse_success += 1\n",
    "        gen_hashes += x[2]\n",
    "        false_alarm_hashes += x[3]\n",
    "        success_hashes += x[4]\n",
    "    end = time.time()\n",
    "    search_time = end - start\n",
    "\n",
    "    shm_start_points.close()\n",
    "    shm_start_points.unlink()\n",
    "    shm_end_points.close()\n",
    "    shm_end_points.unlink()\n",
    "\n",
    "    accuracy = inverse_success / no_iterations\n",
    "    return (\n",
    "        accuracy,\n",
    "        false_alarms,\n",
    "        tables_time,\n",
    "        search_time,\n",
    "        gen_hashes,\n",
    "        false_alarm_hashes,\n",
    "        success_hashes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde845f1-70c2-42cf-a83e-25ffaf120047",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Master method which calls rainbow table and write results as well as times the\n",
    "length of execution\"\"\"\n",
    "\n",
    "\n",
    "def masterMethod(p):\n",
    "    parameters = p\n",
    "    start = time.time()\n",
    "    my_results = fixed_len_dpt(\n",
    "        no_tables=parameters[0],\n",
    "        no_chains=parameters[1],\n",
    "        chain_len=parameters[2],\n",
    "        no_iterations=parameters[3],\n",
    "        hash_size=parameters[4],\n",
    "    )\n",
    "    end = time.time()\n",
    "\n",
    "    # accuracy\n",
    "    parameters.append(my_results[0] * 100)\n",
    "\n",
    "    # false_alarms\n",
    "    parameters.append(my_results[1])\n",
    "\n",
    "    # general hashes\n",
    "    parameters.append(my_results[4])\n",
    "\n",
    "    # false alarm hashes\n",
    "    parameters.append(my_results[5])\n",
    "\n",
    "    # success hashes\n",
    "    parameters.append(my_results[6])\n",
    "\n",
    "    # tables generation time\n",
    "    parameters.append(my_results[2])\n",
    "\n",
    "    # search algorithm time\n",
    "    parameters.append(my_results[3])\n",
    "\n",
    "    # total execution time\n",
    "    total_time = end - start\n",
    "    parameters.append(total_time)\n",
    "\n",
    "    # write file\n",
    "    writeResults(parameters)\n",
    "    print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "480a1495-c90b-42bb-ac51-e536e10eeb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad pass!\n",
      "bad pass!\n",
      "bad pass!\n",
      "bad pass!\n",
      "bad pass!\n",
      "bad pass!\n",
      "bad pass!\n",
      "bad pass!\n",
      "bad pass!\n",
      "bad pass!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Synchronized objects should only be shared between processes through inheritance",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\prajw\\anaconda3\\envs\\updated_hash_inversion\\Lib\\multiprocessing\\queues.py\", line 262, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"C:\\Users\\prajw\\anaconda3\\envs\\updated_hash_inversion\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^\n  File \"C:\\Users\\prajw\\anaconda3\\envs\\updated_hash_inversion\\Lib\\multiprocessing\\sharedctypes.py\", line 199, in __reduce__\n    assert_spawning(self)\n    ~~~~~~~~~~~~~~~^^^^^^\n  File \"C:\\Users\\prajw\\anaconda3\\envs\\updated_hash_inversion\\Lib\\multiprocessing\\context.py\", line 374, in assert_spawning\n    raise RuntimeError(\n    ...<2 lines>...\n        )\nRuntimeError: Synchronized objects should only be shared between processes through inheritance\nwhen serializing tuple item 9\nwhen serializing dict item 'args'\nwhen serializing concurrent.futures.process._CallItem state\nwhen serializing concurrent.futures.process._CallItem object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m parameters = [\u001b[32m5\u001b[39m, \u001b[32m337\u001b[39m, \u001b[32m41\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m16\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# parameters = [255, 10355, 1625, 100, 32]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmasterMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mmasterMethod\u001b[39m\u001b[34m(p)\u001b[39m\n\u001b[32m      6\u001b[39m parameters = p\n\u001b[32m      7\u001b[39m start = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m my_results = \u001b[43mfixed_len_dpt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mno_tables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mno_chains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchain_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mno_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhash_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m end = time.time()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# accuracy\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mfixed_len_dpt\u001b[39m\u001b[34m(no_tables, no_chains, chain_len, no_iterations, hash_size)\u001b[39m\n\u001b[32m     52\u001b[39m start = time.time()\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(no_iterations):\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     x = \u001b[43msearch_tables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmy_passwords\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmy_passwords\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mend_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mno_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mno_chains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchain_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhash_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     false_alarms += x[\u001b[32m1\u001b[39m]\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[32m0\u001b[39m]:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36msearch_tables\u001b[39m\u001b[34m(tp, y, start_points, end_points, no_tables, no_chains, chain_length, input_size)\u001b[39m\n\u001b[32m     31\u001b[39m futures = [\n\u001b[32m     32\u001b[39m     executor.submit(\n\u001b[32m     33\u001b[39m         defs.search_chains,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(no_tables)\n\u001b[32m     46\u001b[39m ]\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent.futures.as_completed(futures):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     result = \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result[\u001b[32m0\u001b[39m]:\n\u001b[32m     50\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m tp == result[\u001b[32m5\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\updated_hash_inversion\\Lib\\concurrent\\futures\\_base.py:443\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\updated_hash_inversion\\Lib\\concurrent\\futures\\_base.py:395\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    397\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    398\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\updated_hash_inversion\\Lib\\multiprocessing\\queues.py:262\u001b[39m, in \u001b[36mQueue._feed\u001b[39m\u001b[34m(buffer, notempty, send_bytes, writelock, reader_close, writer_close, ignore_epipe, onerror, queue_sem)\u001b[39m\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[38;5;66;03m# serialize the data before acquiring the lock\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m obj = \u001b[43m_ForkingPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wacquire \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    264\u001b[39m     send_bytes(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\updated_hash_inversion\\Lib\\multiprocessing\\reduction.py:51\u001b[39m, in \u001b[36mForkingPickler.dumps\u001b[39m\u001b[34m(cls, obj, protocol)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     50\u001b[39m     buf = io.BytesIO()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m buf.getbuffer()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\updated_hash_inversion\\Lib\\multiprocessing\\sharedctypes.py:199\u001b[39m, in \u001b[36mSynchronizedBase.__reduce__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__reduce__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[43massert_spawning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m synchronized, (\u001b[38;5;28mself\u001b[39m._obj, \u001b[38;5;28mself\u001b[39m._lock)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\updated_hash_inversion\\Lib\\multiprocessing\\context.py:374\u001b[39m, in \u001b[36massert_spawning\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34massert_spawning\u001b[39m(obj):\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m get_spawning_popen() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    375\u001b[39m             \u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m objects should only be shared between processes\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    376\u001b[39m             \u001b[33m'\u001b[39m\u001b[33m through inheritance\u001b[39m\u001b[33m'\u001b[39m % \u001b[38;5;28mtype\u001b[39m(obj).\u001b[34m__name__\u001b[39m\n\u001b[32m    377\u001b[39m             )\n",
      "\u001b[31mRuntimeError\u001b[39m: Synchronized objects should only be shared between processes through inheritance",
      "when serializing tuple item 9",
      "when serializing dict item 'args'",
      "when serializing concurrent.futures.process._CallItem state",
      "when serializing concurrent.futures.process._CallItem object"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parameters = [5, 337, 41, 100, 16]\n",
    "    # parameters = [255, 10355, 1625, 100, 32]\n",
    "    masterMethod(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6241b002-edf8-4bdf-abdd-d5f1ddc32828",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_password_extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299730f7-22eb-4cbd-b27f-fc8e38acec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_colliding_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3e7f9-0c5d-4d3c-8c35-5afc941a4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_string = list_of_colliding_hashes[1][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
